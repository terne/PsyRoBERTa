{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "import re"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient#, Input, command\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from utils import azure_ml_configs\n",
        "\n",
        "workspace_id = azure_ml_configs.workspace_id\n",
        "subscription_id = azure_ml_configs.subscription_id\n",
        "resource_group = azure_ml_configs.resource_group\n",
        "workspace_name = azure_ml_configs.workspace_name\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")\n",
        "\n",
        "data_asset = ml_client.data.get(name=\"clinicalNote_AcuteReadmission\", version=1) \n",
        "print(f\"Data asset URI: {data_asset.path}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# args\n",
        "discharge_notes_only = False"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc(text):\n",
        "    # removing some punctuation and lower-casing\n",
        "    punct = \",.:;\\\"\" \n",
        "    text = re.sub('\\s+',' ',text.lower())\n",
        "    text = text.translate(str.maketrans('', '', punct))\n",
        "    return text"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and prepraring data\n",
        "cols = [\"text_names_removed_step2\", \"Acute\", \"set\", \"Type\", \"PatientDurableKey\", \"EncounterKey\", \"CreationInstant\"]\n",
        "df = pd.read_csv(data_asset.path, usecols=cols)\n",
        "# make sure the data is sorted by patient id, encounter and date\n",
        "df.sort_values(by=[\"PatientDurableKey\", \"EncounterKey\", \"CreationInstant\"],inplace=True)\n",
        "#rename main columns of interest\n",
        "df.rename(columns={\"text_names_removed_step2\": \"text\", \"Acute\": \"label\"}, inplace=True)\n",
        "\n",
        "print(len(df.EncounterKey.unique()))\n",
        "\n",
        "if discharge_notes_only:\n",
        "    df = df[df[\"Type\"].str.contains(\"Udskrivningsresume|Udskrivningsresum√©\")==True].copy()\n",
        "\n",
        "df[\"text\"] = df.text.apply(lambda x: preproc(x))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = (df[df.set==\"train\"].text.values,\n",
        "                                                  df[df.set==\"val\"].text.values,\n",
        "                                                  df[df.set==\"test\"].text.values,\n",
        "                                                  df[df.set==\"train\"].label.values,\n",
        "                                                  df[df.set==\"val\"].label.values,\n",
        "                                                  df[df.set==\"test\"].label.values\n",
        "                                                 )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# creating indices for grid search to use the predefined validation set for validation\n",
        "\n",
        "split_index = [-1]*len(X_train)+[0]*len(X_val)\n",
        "X = np.concatenate((X_train, X_val), axis=0)\n",
        "y = np.concatenate((y_train, y_val), axis=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search\n",
        "\n",
        "pds = PredefinedSplit(split_index)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer()), \n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(random_state=0,\n",
        "                               solver='saga',\n",
        "                               #C=np.inf, #C=np.inf to fit without regularization\n",
        "                               max_iter=10000,\n",
        "                               #n_jobs=5\n",
        "                               class_weight=\"balanced\"\n",
        "                              )),\n",
        "])\n",
        "\n",
        "param_grid = {\"vect__max_features\": [5000],\n",
        "             \"vect__ngram_range\": [(1,1), (1,2), (1,3), (1,4)],\n",
        "             \"tfidf__use_idf\": [True, False]\n",
        "             }\n",
        "\n",
        "search = GridSearchCV(pipeline, \n",
        "                      param_grid, \n",
        "                      scoring={\"AP\":\"average_precision\",\"AUC\": \"roc_auc\"}, \n",
        "                      cv=pds, # specifing the predifined split for validation\n",
        "                      refit=\"AP\",\n",
        "                      return_train_score=True,\n",
        "                      verbose=10,\n",
        "                      n_jobs=40)\n",
        "\n",
        "search.fit(X,y)\n",
        "\n",
        "print('Best parameter set: %s ' % search.best_params_)\n",
        "print('Best score: ',search.best_score_)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-fitting best and saving results (coefficients)\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=5000)\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_val_vect = vectorizer.transform(X_val)\n",
        "# save features\n",
        "feats = ['_'.join(s.split()) for s in vectorizer.get_feature_names()]\n",
        "\n",
        "clf =  LogisticRegression(random_state=0,\n",
        "                               solver='saga',\n",
        "                               #C=np.inf, #C=np.inf to fit without regularization\n",
        "                               max_iter=10000,\n",
        "                               class_weight=\"balanced\",\n",
        "                             n_jobs=40)\n",
        "clf.fit(X_train_vect,y_train)\n",
        "\n",
        "allcoefs = pd.DataFrame.from_records(clf.coef_, columns=feats)\n",
        "allcoefs.to_csv(\"logreg_all_coefs_NOT_dedup.csv\", sep=\"\\t\", index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "preds_val = clf.predict(X_val_vect)\n",
        "preds_test = clf.predict(X_test_vect)\n",
        "preds_train = clf.predict(X_train_vect)\n",
        "\n",
        "probs_val = clf.predict_proba(X_val_vect)\n",
        "pos_probs_val = probs_val[:,1:].flatten()\n",
        "\n",
        "probs_train = clf.predict_proba(X_train_vect)\n",
        "pos_probs_train = probs_train[:,1:].flatten()\n",
        "\n",
        "probs_test = clf.predict_proba(X_test_vect)\n",
        "pos_probs_test = probs_test[:,1:].flatten()\n",
        "\n",
        "\n",
        "def get_temp_df(df,pos_probs, labels, split):\n",
        "    p_e = []\n",
        "    ps = df[df.set==split].PatientDurableKey.values\n",
        "    es = df[df.set==split].EncounterKey.values\n",
        "    \n",
        "    for p,e in list(zip(ps,es)):\n",
        "        pe = str(p)+\"_\"+str(e)\n",
        "        p_e.append(pe)\n",
        "    \n",
        "    votedf = pd.DataFrame({\"ID\":p_e, \n",
        "                           \"Label\":labels,\n",
        "                           \"pred_score\": pos_probs})\n",
        "    \n",
        "    p_mean = votedf.groupby([\"ID\"],as_index=False).mean()[\"pred_score\"].values\n",
        "    p_max = votedf.groupby([\"ID\"],as_index=False).max()[\"pred_score\"].values\n",
        "    ids = votedf.groupby([\"ID\"],as_index=False).max()[\"ID\"].values\n",
        "    n = votedf.groupby([\"ID\"],as_index=False).count()[\"pred_score\"].values\n",
        "    target = votedf.groupby([\"ID\"],as_index=False).max()[\"Label\"].values\n",
        "    \n",
        "    temp = pd.DataFrame({\"ID\":ids,\"target\":target,\"p_mean\":p_mean,\"p_max\":p_max,\"n\":n})\n",
        "    \n",
        "    c=2\n",
        "    \n",
        "    temp[\"p\"] = temp.apply(lambda row: (row[\"p_max\"]+row[\"p_mean\"]*(row[\"n\"]/c))/(1+(row[\"n\"]/c)), axis=1)\n",
        "    \n",
        "    return temp"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "temp_test = get_temp_df(df,pos_probs_test, y_test, \"test\")\n",
        "temp_test.to_csv(\"LogRegAllNotDeDupBest_temp_test.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# setting path\n",
        "sys.path.append('..')\n",
        "from utils.eval_utils import plot_auc_curve, MCCF1_threshold_and_metrics\n",
        "\n",
        "model_name = \"Logistic Regression (All notes)\"\n",
        "\n",
        "temp_train = get_temp_df(df,pos_probs_train, y_train, \"train\")\n",
        "temp_val = get_temp_df(df,pos_probs_val, y_val, \"val\")\n",
        "temp_test = get_temp_df(df,pos_probs_test, y_test, \"test\")\n",
        "\n",
        "t=0.5\n",
        "\n",
        "print(\"TEST RESULTS\")\n",
        "plot_auc_curve(temp_test, model_name)\n",
        "MCCF1_threshold_and_metrics(temp_train, temp_test,threshold=t, show_train_performance=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}