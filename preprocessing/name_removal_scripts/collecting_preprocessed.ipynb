{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_files = [\"../data/processed_notes/clinicalNote44M_NamesRemoved_261123_{}.csv\".format(i) for i in range(0,16)]\n",
        "\n",
        "li = []\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "\n",
        "frame.to_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading processed data to Azure data store\n",
        "from azureml.fsspec import AzureMachineLearningFileSystem\n",
        "path_researcherdata = \"PATH TO RESEARCHER DATA FOLDER IN DATA STORE\"\n",
        "fs = AzureMachineLearningFileSystem(path_researcherdata)\n",
        "fs.upload(lpath=\"../data/processed_notes/clinicalNote44M_NamesRemoved.csv\", rpath=\"./\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing preproccesed datasets for pretraining\n",
        "Removing patients from acute readmission prediction val and test set"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient#, Input, command\n",
        "from azure.identity import DefaultAzureCredential\n",
        "sys.path.append(\"../..\")\n",
        "from utils import azure_ml_configs\n",
        "\n",
        "workspace_id = azure_ml_configs.workspace_id\n",
        "subscription_id = azure_ml_configs.subscription_id\n",
        "resource_group = azure_ml_configs.resource_group\n",
        "workspace_name = azure_ml_configs.workspace_name\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")\n",
        "\n",
        "data_asset = ml_client.data.get(name=\"clinicalNote44M_NamesRemoved\", version=1) \n",
        "print(f\"Data asset URI: {data_asset.path}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"PatientDurableKey\", \"EncounterKey\",\"text_names_removed_step2\", \"CreationInstant\", \"LastEditedInstant\"]\n",
        "df = pd.read_csv(data_asset.path, usecols=cols)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "acutedf = pd.read_csv(\"../data/acuteReadmission/clinicalNote_AcuteReadmissions_NamesRemoved_161023.csv\", usecols=[\"PatientDurableKey\", \"EncounterKey\", \"set\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_p = acutedf[acutedf.set==\"train\"].PatientDurableKey.unique()\n",
        "val_p = acutedf[acutedf.set==\"val\"].PatientDurableKey.unique()\n",
        "test_p = acutedf[acutedf.set==\"test\"].PatientDurableKey.unique()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "notes_wo_valtest = df[~df.PatientDurableKey.isin(test_p.tolist()+val_p.tolist())]\n",
        "\n",
        "notes_wo_valtest.to_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train.txt\", \"w+\") as f:\n",
        "    for i, text in enumerate(tqdm(notes_wo_valtest.text_names_removed_step2.values)):\n",
        "        if i==len(notes_wo_valtest)-1:\n",
        "            f.write(text)\n",
        "        else:\n",
        "            f.write(text+\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fs.upload(lpath=\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train.txt\", rpath=\"./\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dividing pretraining data into four parts with seperate patients"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train.csv\",index_col=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique patient ids\n",
        "samplelist = train[\"PatientDurableKey\"].unique()    \n",
        "\n",
        "# make train, val and test samples based on shuffled patient ids\n",
        "train_A, train_B = train_test_split(samplelist, test_size=0.5, random_state=5, shuffle=True)\n",
        "\n",
        "train_1, train_2 = train_test_split(train_A, test_size=0.5, random_state=5)\n",
        "train_3, train_4 = train_test_split(train_B, test_size=0.5, random_state=5)\n",
        "\n",
        "# check num patients in each and the percentage size of each set\n",
        "print(len(train_1), len(train_2), len(train_3), len(train_4))\n",
        "print(len(train_1)/len(samplelist), len(train_2)/len(samplelist), len(train_3)/len(samplelist), len(train_4)/len(samplelist))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train1 = train[train.PatientDurableKey.isin(train_1)]\n",
        "train1.to_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart1.csv\")\n",
        "\n",
        "train2 = train[train.PatientDurableKey.isin(train_2)]\n",
        "train2.to_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart2.csv\")\n",
        "\n",
        "train3 = train[train.PatientDurableKey.isin(train_3)]\n",
        "train3.to_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart3.csv\")\n",
        "\n",
        "train4 = train[train.PatientDurableKey.isin(train_4)]\n",
        "train4.to_csv(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart4.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for indel, df in enumerate([train1,train2,train3,train4]):\n",
        "    print(indel+1)\n",
        "    with open(\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart{}.txt\".format(indel+1), \"w+\") as f:\n",
        "        for i, text in enumerate(tqdm(df.text_names_removed_step2.values)):\n",
        "            if i==len(df)-1:\n",
        "                f.write(text)\n",
        "            else:\n",
        "                f.write(text+\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.fsspec import AzureMachineLearningFileSystem\n",
        "\n",
        "path_researcherdata = \"PATH TO RESEARCHER DATA FOLDER IN DATA STORE\"\n",
        "fs = AzureMachineLearningFileSystem(path_researcherdata)\n",
        "\n",
        "fs.upload(lpath=\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart1.txt\", rpath=\"./\")\n",
        "fs.upload(lpath=\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart2.txt\", rpath=\"./\")\n",
        "fs.upload(lpath=\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart3.txt\", rpath=\"./\")\n",
        "fs.upload(lpath=\"../data/processed_notes/clinicalNote44M_NamesRemoved_MLM_train_randompart4.txt\", rpath=\"./\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}