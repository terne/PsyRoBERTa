{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# check to see if safetensors work\n",
        "from safetensors import safe_open"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "import random\n",
        "import pandas as pd\n",
        "from attention_flow_and_rollout import compute_joint_attention\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient#, Input, command\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "sys.path.append(\"../..\")\n",
        "from utils import azure_ml_configs\n",
        "\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=azure_ml_configs.subscription_id,\n",
        "    resource_group_name=azure_ml_configs.resource_group,\n",
        "    workspace_name=azure_ml_configs.workspace_name,\n",
        ")\n",
        "\n",
        "#data_asset = ml_client.data.get(name=\"clinicalNote_AcuteReadmission_DedupCont\", version=1)\n",
        "data_asset = ml_client.data.get(name=\"clinicalNote_AcuteReadmission\", version=1)\n",
        "\n",
        "print(f\"Data asset URI: {data_asset.path}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument(\"--data\", type=str, default=None)\n",
        "parser.add_argument(\"--pretrained_model_path\", type=str, default=\"../\")\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"psyroberta_for_acute_readmission_prediction\")\n",
        "parser.add_argument(\"--checkpoint_dir\", type=str)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64)\n",
        "parser.add_argument(\"--nrows\", type=int, default=None, help=\"To load only n rows from data for development tests.\")\n",
        "parser.add_argument(\"--shuffle\", action=\"store_true\")\n",
        "parser.add_argument(\"--discharge_notes_only\",\n",
        "                    action=\"store_true\",\n",
        "                    help=\"If passed, filters data to only include discharge summaries.\")\n",
        "parser.add_argument(\"--max_seq_splits\", \n",
        "                    type=int, \n",
        "                    default=None, \n",
        "                    help=\"The number of splits that long notes will be split to. Default None means that every part of a long note is included. However, some notes are extremely long (tens of thousands tokens) compared to the majority (median ~130 tokens). Based on descriptive analysis of sequence lengths across regions and psychiatric centers, max_seq_splits=4 might be appropriate, because for the center with longest notes, 75% of are less than 1600 tokens long.\")\n",
        "parser.add_argument(\"--scale_loss\", action=\"store_true\")\n",
        "parser.add_argument(\"--on_test\", action=\"store_true\")\n",
        "parser.add_argument(\n",
        "        \"--with_tracking\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to enable experiment trackers for logging.\",\n",
        "    )\n",
        "parser.add_argument(\"--random_seed\", type=int, default=42)\n",
        "parser.add_argument(\"--text_column_name\", type=str, default=\"text_names_removed_step2\")\n",
        "\n",
        "\n",
        "args = parser.parse_args([\"--model_name\", \"psyroberta_p4_epoch12\",\n",
        "                          \"--pretrained_model_path\", \"../../finetuning/acutereadm_finetuned_models/\",\n",
        "                          \"--data\", data_asset.path,\n",
        "                          \"--checkpoint_dir\", \"../../result_files/\",\n",
        "                          \"--batch_size\", \"1\",\n",
        "                          \"--random_seed\", \"22\",\n",
        "                          #\"--text_column_name\", \"DedupCont\", \n",
        "                          \"--discharge_notes_only\",\n",
        "                          \"--scale_loss\",\n",
        "                          \"--on_test\"\n",
        "                         ])\n",
        "\n",
        "print(args, \"\\n\")\n",
        "data_path = args.data\n",
        "model_path = args.pretrained_model_path\n",
        "\n",
        "if args.discharge_notes_only:\n",
        "    directory = \"dischargesum\"\n",
        "else:\n",
        "    directory = \"allnotes\" \n",
        "\n",
        "model_name = args.model_name\n",
        "epoch = 11\n",
        "checkpoint_dir = args.checkpoint_dir # with azure, should be within \"./outputs\"\n",
        "batch_size = args.batch_size\n",
        "\n",
        "print(\"max_seq_splits=\", args.max_seq_splits)\n",
        "print(\"disharge notes only =\", args.discharge_notes_only)\n",
        "print(\"model:\", model_path+directory+\"/\"+model_name)\n",
        "\n",
        "# setting random seeds\n",
        "np.random.seed(args.random_seed)\n",
        "random.seed(args.random_seed)\n",
        "torch.manual_seed(args.random_seed)\n",
        "torch.cuda.manual_seed_all(args.random_seed)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# randomness for DataLoader, see https://pytorch.org/docs/stable/notes/randomness.html\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(args.random_seed)\n",
        "\n",
        "#device = torch.device(\"cuda:0\")\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path+directory+\"/\"+model_name, \n",
        "                                                            local_files_only=True,\n",
        "                                                            use_safetensors=True, \n",
        "                                                            output_hidden_states=True,\n",
        "                                                            output_attentions=True).cuda()\n",
        "#model = torch.compile(model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path+directory+\"/\"+model_name, local_files_only=True)\n",
        "\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and prepraring data\n",
        "cols = [args.text_column_name, \"Acute\", \"set\", \"Type\", \"PatientDurableKey\", \"EncounterKey\", \"CreationInstant\"]\n",
        "df = pd.read_csv(data_path, usecols=cols, nrows=args.nrows)\n",
        "# make sure the data is sorted by patient id, encounter and date\n",
        "df.sort_values(by=[\"PatientDurableKey\", \"EncounterKey\", \"CreationInstant\"],inplace=True)\n",
        "#rename main columns of interest\n",
        "df.rename(columns={args.text_column_name: \"text\", \"Acute\": \"label\"}, inplace=True)\n",
        "\n",
        "if args.discharge_notes_only:\n",
        "    df = df[df[\"Type\"].str.contains(\"Udskrivningsresume|Udskrivningsresum√©\")==True].copy()\n",
        "    # to do: take 1 when there are more than 1.\n",
        "\n",
        "# concatenating texts on patient and encounter id\n",
        "df = df.groupby([\"PatientDurableKey\", \"EncounterKey\", \"label\", \"set\"]).text.apply(f'{tokenizer.sep_token}'.join).reset_index()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {\n",
        "    \"train\": Dataset.from_pandas(df[df.set==\"train\"]),\n",
        "    \"validation\": Dataset.from_pandas(df[df.set==\"val\"]),\n",
        "    \"test\": Dataset.from_pandas(df[df.set==\"test\"])\n",
        "    }\n",
        "\n",
        "\n",
        "raw_datasets = DatasetDict(data_dict)\n",
        "\n",
        "text_column_name = \"text\"\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    labs = []\n",
        "    patientids = []\n",
        "    encounterids = []\n",
        "    texts = []\n",
        "    for x,y, patient_id, encounter_id in list(zip(examples[\"text\"], examples[\"label\"], examples[\"PatientDurableKey\"], examples[\"EncounterKey\"])):\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            x,  # Sentence to encode\n",
        "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]' or equivelant for roberta\n",
        "            max_length=512,  # Pad & truncate all sentences.\n",
        "            padding=\"max_length\", #(needing to specify truncation=True depends on version)\n",
        "            truncation=True,\n",
        "            return_overflowing_tokens=True, # return lists of tokens above 512 \n",
        "            return_offsets_mapping=True,\n",
        "            stride=32, # The stride used when the context is too large and is split across several features.\n",
        "            return_attention_mask=True,  # Construct attn. masks.\n",
        "            return_tensors='pt'  # Return pytorch tensors.\n",
        "        )\n",
        "        for inputs, attentions in list(zip(encoded_dict['input_ids'],encoded_dict['attention_mask']))[:args.max_seq_splits]:\n",
        "            #print(i.shape)\n",
        "            # Add the encoded sentence to the list.\n",
        "            input_ids.append(inputs)\n",
        "            texts.append(tokenizer.decode(inputs))\n",
        "            #And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(attentions)\n",
        "            labs.append(y)\n",
        "            patientids.append(patient_id)\n",
        "            encounterids.append(encounter_id)\n",
        "    assert len(input_ids) == len(attention_masks) == len(labs) == len(patientids) == len(encounterids)\n",
        "    sample = {\"inputs\": input_ids,\n",
        "            \"attn_masks\": attention_masks,\n",
        "            \"labels\": labs,\n",
        "            \"patient_id\": patientids,\n",
        "            \"encounter_id\": encounterids,\n",
        "            \"text_split\":texts}\n",
        "    return sample"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "            tokenize_function,\n",
        "            batched=True,\n",
        "            num_proc=None,\n",
        "            remove_columns=raw_datasets['validation'].column_names,\n",
        "            #load_from_cache_file=not args.overwrite_cache,\n",
        "            desc=\"Running tokenizer on every text in dataset\",\n",
        "        )\n",
        "\n",
        "tokenized_datasets[\"train\"].set_format(type='pt', columns=['inputs', 'attn_masks', 'labels', 'patient_id', 'encounter_id'])\n",
        "tokenized_datasets[\"validation\"].set_format(type='pt',output_all_columns=True, columns=['inputs', 'attn_masks', 'labels', 'patient_id', 'encounter_id'])\n",
        "tokenized_datasets[\"test\"].set_format(type='pt', output_all_columns=True, columns=['inputs', 'attn_masks', 'labels', 'patient_id', 'encounter_id'])\n",
        "\n",
        "traindata = tokenized_datasets[\"train\"]\n",
        "valdata = tokenized_datasets[\"validation\"]\n",
        "testdata = tokenized_datasets[\"test\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders():\n",
        "    \n",
        "    train_dataloader = DataLoader(dataset=traindata, \n",
        "                                    shuffle=args.shuffle, \n",
        "                                    batch_size=batch_size,\n",
        "                                    #num_workers=0,\n",
        "                                    worker_init_fn=seed_worker,\n",
        "                                    generator=g)\n",
        "\n",
        "    val_dataloader = DataLoader(dataset=valdata, \n",
        "                                    shuffle=args.shuffle, \n",
        "                                    batch_size=batch_size,\n",
        "                                    #num_workers=0,\n",
        "                                    worker_init_fn=seed_worker,\n",
        "                                    generator=g)\n",
        "\n",
        "    test_dataloader = DataLoader(dataset=testdata, \n",
        "                                    shuffle=args.shuffle, \n",
        "                                    batch_size=batch_size,\n",
        "                                    #num_workers=0,\n",
        "                                    worker_init_fn=seed_worker,\n",
        "                                    generator=g)\n",
        "        \n",
        "    return train_dataloader,val_dataloader,test_dataloader"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def accelerate_forward_and_explain(model):\n",
        "    \n",
        "    accelerator_log_kwargs = {}\n",
        "    if args.with_tracking:\n",
        "        accelerator_log_kwargs[\"log_with\"] = args.report_to\n",
        "        accelerator_log_kwargs[\"project_dir\"] = args.log_dir #args.output_dir\n",
        "\n",
        "    accelerator = Accelerator(**accelerator_log_kwargs)\n",
        "\n",
        "    if accelerator.is_local_main_process:\n",
        "        datasets.utils.logging.set_verbosity_warning()\n",
        "        transformers.utils.logging.set_verbosity_info()\n",
        "    else:\n",
        "        datasets.utils.logging.set_verbosity_error()\n",
        "        transformers.utils.logging.set_verbosity_error()\n",
        "    \n",
        "    train_dataloader, val_dataloader, test_dataloader = create_dataloaders()\n",
        "    \n",
        "    \n",
        "    model, train_dataloader, val_dataloader, test_dataloader = accelerator.prepare(\n",
        "        model, train_dataloader, val_dataloader, test_dataloader\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    def attention_rollout(all_attentions, inputs):\n",
        "        #tokens = tokenizer.convert_ids_to_tokens(inputs.tolist()[0])\n",
        "        _attentions = [att.detach().cpu().numpy() for att in all_attentions]\n",
        "        attentions_mat = np.stack(_attentions, axis=0).squeeze()\n",
        "        #print(\"attn shape:\", attentions_mat.shape)\n",
        "        res_att_mat = attentions_mat.sum(axis=1)/attentions_mat.shape[1]\n",
        "        joint_attentions = compute_joint_attention(res_att_mat, add_residual=True)\n",
        "        \n",
        "        return joint_attentions[-1].sum(axis=0)\n",
        "\n",
        "\n",
        "    def run_attention_rollout(dataloader):\n",
        "        model.eval()\n",
        "        tokens_attentions = []\n",
        "        for batch in tqdm(dataloader):\n",
        "            #print(batch)\n",
        "            inputs, attn, targets = batch[\"inputs\"],batch[\"attn_masks\"], batch[\"labels\"]\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs.cuda(), attention_mask=attn.cuda(), labels=targets.cuda())\n",
        "            \n",
        "            all_hidden_states, all_attentions =  outputs['hidden_states'], outputs['attentions']\n",
        "            all_attentions, all_token_ids = accelerator.gather_for_metrics((all_attentions, inputs))\n",
        "            att_rollout = attention_rollout(all_attentions,all_token_ids)\n",
        "            tokens = tokenizer.convert_ids_to_tokens(all_token_ids.cpu()[0])\n",
        "            assert len(tokens)==len(all_token_ids.cpu()[0])==len(att_rollout)\n",
        "            \n",
        "            #print(len(all_token_ids.cpu()[0]), len(att_rollout))\n",
        "            \n",
        "            probabilities = nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            probabilities, references = accelerator.gather_for_metrics((probabilities,batch[\"labels\"]))\n",
        "\n",
        "\n",
        "            predictions = np.argmax(probabilities.detach().cpu(), axis=1).flatten()\n",
        "            #predictions = torch.argmax(probabilities.detach().cpu()).flatten()\n",
        "            \n",
        "            pos_probs = probabilities[:,1:].flatten().item()\n",
        "            #print(pos_probs)\n",
        "            \n",
        "            pid, eid = accelerator.gather_for_metrics((batch[\"patient_id\"], batch[\"encounter_id\"]))\n",
        "            \n",
        "            tokens_attentions.append({\"token_ids\":all_token_ids.cpu()[0].tolist(),\n",
        "                                      \"tokens\": tokens,\n",
        "                                      \"attn_rollout\":att_rollout.tolist(),\n",
        "                                      \"pos_prob\": pos_probs,\n",
        "                                      \"pid\": pid.item(),\n",
        "                                      \"eid\": eid.item(),\n",
        "                                      \"text\": tokenizer.decode(all_token_ids.cpu()[0])})\n",
        "           \n",
        "\n",
        "        #print(tokens_attentions[:10])\n",
        "        return tokens_attentions\n",
        "    \n",
        "    \n",
        "    \n",
        "    attn_train = run_attention_rollout(train_dataloader)\n",
        "    attn_train_df = pd.DataFrame(attn_train)\n",
        "    if accelerator.is_main_process:\n",
        "        attn_train_df.to_csv(f'../../result_files/{directory}_{model_name}_AR_train_results.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import notebook_launcher\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "notebook_launcher(accelerate_forward_and_explain, (model,), num_processes=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}