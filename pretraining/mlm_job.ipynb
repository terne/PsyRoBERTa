{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, ScriptRunConfig, Environment, Datastore\n",
        "from azureml.core.script_run_config import ScriptRunConfig\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "import azureml._restclient.snapshots_client\n",
        "from azureml.fsspec import AzureMachineLearningFileSystem\n",
        "import mlflow"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient#, Input, command\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from utils import azure_ml_configs\n",
        "\n",
        "workspace_id =  azure_ml_configs.workspace_id\n",
        "subscription_id = azure_ml_configs.subscription_id\n",
        "resource_group = azure_ml_configs.resource_group\n",
        "workspace_name = azure_ml_configs.workspace_name\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#data_asset = ml_client.data.get(name=\"clinicalNote44M_pretraindata_randompart1\", version=2) \n",
        "\n",
        "#data_asset = ml_client.data.get(name=\"clinicalNote44M_pretraindata_randompart2\", version=2) \n",
        "\n",
        "#data_asset = ml_client.data.get(name=\"clinicalNote44M_pretraindata_randompart3\", version=2) \n",
        "\n",
        "data_asset = ml_client.data.get(name=\"clinicalNote44M_pretraindata_randompart4\", version=2) \n",
        "print(f\"Data asset URI: {data_asset.path}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# get workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Create an Experiment\n",
        "experiment_name = 'mlm-jobs'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "\n",
        "# Set the desired snapshot size (in bytes)\n",
        "snapshot_size = 10073741824\n",
        "# Update the maximum snapshot size\n",
        "azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = snapshot_size\n",
        "\n",
        "\n",
        "# Get the Curated Environment\n",
        "curated_env = Environment.get(workspace=ws, name=\"AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu\") #\"AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu\"\n",
        "\n",
        "\n",
        "command = \"pip install -r mlm_requirements.txt && accelerate launch --multi_gpu --mixed_precision 'fp16' --num_processes 4 \\\n",
        "run_mlm_no_trainer.py \\\n",
        "--model_name_or_path 'psyroberta/psyroberta_part3' \\\n",
        "--train_file '{}' \\\n",
        "--azure_data_asset \\\n",
        "--max_seq_length 512 \\\n",
        "--validation_split_percentage 5 \\\n",
        "--per_device_train_batch_size 64 \\\n",
        "--per_device_eval_batch_size 64 \\\n",
        "--seed 21 \\\n",
        "--output_dir './outputs' \\\n",
        "--with_tracking \\\n",
        "--report_to 'mlflow' \\\n",
        "--log_dir './logs' \\\n",
        "--checkpointing_steps 2000 \\\n",
        "--num_train_epochs 3\".format(data_asset.path)\n",
        "\n",
        "#--num_warmup_steps 1000 \\\n",
        "\n",
        "print(command)\n",
        "\n",
        "# --model_name_or_path # was first 'psyroberta/psyroberta_part1', then 'psyroberta/psyroberta_part2' and lastly 'psyroberta/psyroberta_part3', which, after training, creates the final psyroberta_part4\n",
        "\n",
        "# for validation, use either\n",
        "# --validation_split_percentage\n",
        "# or\n",
        "# --validation_file val_data_path \n",
        "\n",
        "# argument \"checkpointing_steps\" can be \"epoch\" or a digit signifying for which n steps a checkpoint should be saved.\n",
        "\n",
        "\n",
        "\n",
        "# set up script run configuration\n",
        "config = ScriptRunConfig(\n",
        "    source_directory='.',\n",
        "    command=command,\n",
        "    compute_target='Terne4A100',\n",
        "    environment=curated_env\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# submit script to AML\n",
        "Run = experiment.submit(config)\n",
        "print(Run.get_portal_url()) # link to ml.azure.com\n",
        "Run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}